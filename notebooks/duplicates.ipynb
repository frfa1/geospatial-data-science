{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a61abb6-1d57-4673-b8fa-f5a352c2abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760354f-ccdc-4d77-b522-cacdf9cee751",
   "metadata": {},
   "source": [
    "### Compare number of duplicates in datasets scraped by Python and Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "52bde845-22f5-43f9-b8fa-7611e3fcea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "df_python = pd.read_csv(\"data/17-04-23.csv\")\n",
    "df_go = pd.read_csv(\"data/17-04-23_go.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c50c8b9c-286b-4362-9811-1eb1131744ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframes have the same number of records\n",
    "df_python.id.count() == df_go.id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e5f7aa73-92cc-4676-9d48-483e5d7516eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicates\n",
    "p = df_python.duplicated(subset=[\"id\"])\n",
    "g = df_go.duplicated(subset=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e3bb6423-68af-46f3-846c-0ea2d4dc258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1968 records, scraping with Python resulted in 185 duplicates, and only 46 when using Go\n"
     ]
    }
   ],
   "source": [
    "# Python vs Go\n",
    "print(f\"Out of {df_go.id.count()} records, scraping with Python resulted in {len(df_python[p])} duplicates, and only {len(df_go[g])} when using Go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7931e7-38a8-461a-b246-4e76e3db5b8d",
   "metadata": {},
   "source": [
    "### Minimize the number of duplicates by repeated scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "657847d9-300b-41ec-ad56-df5bd5ce9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "df_a = pd.read_csv(\"data/20-04-23_A.csv\")\n",
    "df_b = pd.read_csv(\"data/20-04-23_B.csv\")\n",
    "df_c = pd.read_csv(\"data/20-04-23_C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7b08684f-e9b7-4123-a048-ce018a3faba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframes have the same number of records\n",
    "df_a.id.count() == df_b.id.count() == df_c.id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9d0530d2-ebce-49ad-bdb9-6f302541668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated records \n",
      "A: 410 \n",
      "B: 141 \n",
      "C: 20\n"
     ]
    }
   ],
   "source": [
    "# Count duplicates\n",
    "a = df_a.duplicated(subset=[\"id\"])\n",
    "b = df_b.duplicated(subset=[\"id\"])\n",
    "c = df_c.duplicated(subset=[\"id\"])\n",
    "print(f\"Duplicated records \\nA: {len(df_a[a])} \\nB: {len(df_b[b])} \\nC: {len(df_c[c])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e7626608-9a53-4874-a303-7622fefc05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append dataframes\n",
    "abc = pd.concat([df_a, df_b, df_c], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b9c49735-2900-49c7-82ce-793f88bdf4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df = abc.drop_duplicates(subset=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a8efaaf-1263-4927-95eb-1bcae60fe332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing records in combined dataframe: 2\n",
      "Original # of records: 2020\n",
      "New number of records: 2018\n"
     ]
    }
   ],
   "source": [
    "# Missing records in \n",
    "print(f\"Missing records in combined dataframe: {df_a.id.count() - df.id.count()}\\nOriginal # of records: {df_a.id.count()}\\nNew number of records: {df.id.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c0814223-3d98-4734-8ef5-690db25cae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case scenario - A:  20.3% missing records\n",
      "Middle scenario - B:  7.0% missing records\n",
      "Best case scenario - C:  1.0% missing records\n",
      "Dataset obtained from all above scenarios:  0.1% missing records\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(f\"Worst case scenario - A: {len(df_a[a]) / df_a.id.count() * 100 : .1f}% missing records\")\n",
    "print(f\"Middle scenario - B: {len(df_b[b]) / df_b.id.count() * 100 : .1f}% missing records\")\n",
    "print(f\"Best case scenario - C: {len(df_c[c]) / df_c.id.count() * 100 : .1f}% missing records\")\n",
    "print(f\"Dataset obtained from all above scenarios: {(df_a.id.count() - df.id.count()) / df.id.count() * 100 : .1f}% missing records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8df7db0f-1913-4629-950f-c05dc903d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save resulting dataset to .csv file\n",
    "# df.to_csv(\"data/20-04-23.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f22062-38c4-4048-b54e-45d28905f47a",
   "metadata": {},
   "source": [
    "### Results\n",
    "By combining data from 3 scrapes we obtained a dataset with only 0.1% of missing records!  \n",
    "Repeated scraping was done using Go : https://github.com/szymongalecki/boligzonen_scraper\n",
    "\n",
    "Scrape times:  \n",
    "- Python:  15 - 30 minutes  \n",
    "- Go: ~4 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
